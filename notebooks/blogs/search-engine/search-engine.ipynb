{
 "cells": [
  {
   "cell_type": "raw",
   "id": "66776dcd-63f1-46d0-8c6c-47aa48b1ab8d",
   "metadata": {},
   "source": [
    "root = 'deep-dive'\n",
    "name = 'search-engines'\n",
    "page = 1\n",
    "authors = 'yash101'\n",
    "title = 'Search Engines - a Beginner-Friendly Deep Dive'\n",
    "subtitle = 'Learn how search engines work and attempt to build your own!'\n",
    "lastModifiedOn = '2025-02-07T20:56:17.277Z'\n",
    "publishedOn = '2025-02-07T00:00:00.277Z'\n",
    "isPublished = true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeffabb-cc8d-4a2f-ad65-5cc45fbf7d9c",
   "metadata": {},
   "source": [
    "Search engines are ubiquitous. Google, Bing, Yahoo, you name it, all of these are internet-wide search engines. Even your favorite social media platforms have a search functionality. How do they work? How can we build our own? And how can we build a search engine which is cheap and easy to run?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fa749a-31fd-4682-97d4-70458e5861c3",
   "metadata": {},
   "source": [
    "# Introduction to the Search Problem\n",
    "\n",
    "Search engines are ubiquitous. Google, Bing, Yahoo, you name it, all of these are internet-wide search engines. Even your favorite social media platforms have a search functionality. How do they work? How can we build our own? And how can we build a search engine which is cheap and easy to run?\n",
    "<br />\n",
    "\n",
    "This article is written with the first-principles approach. Rather than jumping straight into established methods, I'm starting with something familier - a textbook, and building a search engine with the natural patterns I use to find a topic in the textbook. This article takes an iterative approach to achieve a strong, yet simple, search engine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc112895-3b68-4a97-ae71-9e14a591d0ae",
   "metadata": {},
   "source": [
    "## Background üåÖ\n",
    "\n",
    "I wanted to add search functionality to this website, but there‚Äôs a catch - this site is entirely backend-free by design and I intend to keep it that way. Running a backend adds costs, requires maintenance, and introduces scaling challenges, which I want to avoid.\n",
    "\n",
    "Additionally, instead of researching existing search engine architectures, I‚Äôm taking a first-principles approach. Rather than jumping straight into established methods, I‚Äôm starting with something familiar - a textbook. How do I naturally find a topic in a textbook? What patterns do I rely on? By deconstructing my own search process, I aim to build a search engine from scratch, refining it step by step.\n",
    "\n",
    "This article is a log of that journey, an attempt to understand search from the ground up, experiment with solutions, and iteratively improve them along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc61ff0-cb47-49c0-a070-1b822d77ce11",
   "metadata": {},
   "source": [
    "## Goals ‚õ≥Ô∏è\n",
    "\n",
    "Search engines are ubiquitous - almost every major social media platform uses one, and, as the elephant in the room, you have behemoths such as Google, Bing and others. But how do they work? And how can we build our own? And how can we keep it cheap and simple to use?\n",
    "\n",
    "Some goals for this project:\n",
    "\n",
    "* Learn how search engines work\n",
    "* Learn some NLP (natural language processing) techniques\n",
    "* Achieve a decent accuracy\n",
    "\n",
    "Additional challenges and constraints, since I can't keep things simple üòÉ:\n",
    "\n",
    "* Search should have no backend, and be run 100% in the browser\n",
    "* Search should support unicode. Languages other than English exist, oh, and don't forget about Emojis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8dcbfd-3819-4404-93ca-e12411700e14",
   "metadata": {},
   "source": [
    "## Tools Used üõ†Ô∏è\n",
    "\n",
    "* Node.js (v22.13.0)\n",
    "* [Enron Emails Dataset](https://www.cs.cmu.edu/~enron/) - used for large scale test data\n",
    "* [√Üsop's Fables](https://www.gutenberg.org/ebooks/21) - used for test data in our demos\n",
    "* Web Browser with JavaScript support\n",
    "\n",
    "> **Notes**:\n",
    "> \n",
    "> 1. for √Üsop's fables, the text version of the Project Gutenberg archive was transformed into JSON for ease of use. The processing of the Project Gutenberg text is outside the scope of this project, and the processing may have some errors.\n",
    "> 2. The majority of code will be written in JavaScript, due to the goal of being able to run search 100% on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618efa34-1574-4c66-b0a9-c912efa99a7c",
   "metadata": {},
   "source": [
    "## Search, The Problem üëÄ\n",
    "\n",
    "Once upon a time, the internet was in its infancy, Google was still under development, and CLRS, The legendary *Introduction to Algorithms* textbook was just published. But none of that mattered, you had a biology assignment due which required you to understand *prokaryotic organisms*. While the Internet offered little in help, your best resource sat in front of you - **a biology textbook**!\n",
    "\n",
    "Now, take a moment and think... How do you find a topic in a textbook?\n",
    "\n",
    "You *could* read the entire textbook, every single page, and find out more about *prokaryotic organisms*, but is that your best approach? Do you have the time to read through every single page for your assignment? Probably not. Thus, we need to do better and use the resources we have available to ourselves to find a better process.\n",
    "\n",
    "What resources does the textbook provide you to efficiently find what you are looking for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed6bcec-d52d-4ab1-8634-6fd083b821dc",
   "metadata": {},
   "source": [
    "## Search, The Textbook Method üóÇÔ∏è\n",
    "\n",
    "Textbooks normally have two tools, available to your disposal, to help you find information quickly:\n",
    "\n",
    "1. **Table of Contents (TOC)** at the beginning\n",
    "2. **Index** at the end\n",
    "\n",
    "Each of these tools work differently from each other, but together, they make searching for topics much faster than flipping through pages.\n",
    "\n",
    "> The **Table of Contents** is like a roadmap, listing chapters and sections in order, allowing you to navigate through a book top-down.\n",
    "> \n",
    "> For example, if you need to learn about bacteria, the TOC might tell you:\n",
    ">\n",
    "> üìñ Chapter 3: Bacteria and Prokaryotes (Page 45)\n",
    ">\n",
    "> This tells you where to start reading about bacteria. But if you need something very specific‚Äîlike \"Gram-positive bacteria\"‚Äîyou might not find that in the TOC.\n",
    ">\n",
    "> <br />\n",
    "> \n",
    "> The **Index** maps topics and terms to their location. Instead of listing topics by chapters, it lists every single important word or term in **alphabetical order**, along with the exact page numbers.\n",
    ">\n",
    "> For example, if you need *Gram-positive Bacteria*, you can check the index:\n",
    ">\n",
    "> üîç Gram-positive bacteria ‚Äì Pages 26, 28, 47\n",
    ">\n",
    "> Now, you can go straight to the exact pages without reading everything before it.\n",
    "\n",
    "Can we model a simple search engine off the same process used to find a topic in a book?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639478de-2ce7-433a-b9d2-48c646db94df",
   "metadata": {},
   "source": [
    "## Attempting to Create a High-Level Overview üç≥\n",
    "\n",
    "Before diving into implementation, let‚Äôs break down the core components of a search system by asking two key questions:\n",
    "\n",
    "* What components are necessary for search?\n",
    "* What role does each component play?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Data Acquisition üèóÔ∏è\n",
    "Before we can search anything, we need to gather and prepare the data. This involves two key steps:\n",
    "\n",
    "1. üß∫ Gather the data\n",
    "    1. On the internet: render pages, find links and follow links, downloading the rendered website\n",
    "    2. Local: recursively find files in a directory, read them\n",
    "2. üßº Clean up the data - prepare the data so it can be searched\n",
    "    1. Clean up unicode code points\n",
    "    2. Identify meaningful sections and metadata\n",
    "    3. Standardize formatting for consistent searchability\n",
    "\n",
    "Once we acquire and clean up data, we face a design decision: Do we preprocess heavily upfront to enable efficient search later OR do we store raw data and brute-force search at query time?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899d8c9-b0ca-4402-8a22-4f2cd804e340",
   "metadata": {},
   "source": [
    "## [Next: We will Acquire Data and Clean it up ‚è≠Ô∏è](/blog/search-engine-2)\n",
    "\n",
    "In the next section, we will acquire data, clean it up and prepare it for search."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
