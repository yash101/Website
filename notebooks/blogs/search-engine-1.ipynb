{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522d2439-8858-4618-8870-8b2a12930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 'Devyash Lodha'\n",
    "title = 'Building a Search Engine - Part 1'\n",
    "lastModified = '2025-02-07T20:56:17.277Z'\n",
    "published = '2025-02-07T20:56:17.277Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeffabb-cc8d-4a2f-ad65-5cc45fbf7d9c",
   "metadata": {},
   "source": [
    "Search engines are a complex beast. This article is about my process of attempting to build one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c375c5-aad4-49af-9015-c1cade9ff464",
   "metadata": {},
   "source": [
    "## Multipart Series\n",
    "\n",
    "1. [Introduction and get started](/blog/search-engine-1)\n",
    "2. [Reverse Index and Search](/blog/search-engine-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc112895-3b68-4a97-ae71-9e14a591d0ae",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "I wanted to add search functionality to this website. However, this site is backend-free, and that is by design! A backend is another service which costs money to run and requires (occasional) maintenance. This article serves as a log of the things I tried and how I developed my solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc61ff0-cb47-49c0-a070-1b822d77ce11",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Search engines are ubiquitous - almost every major social media platform uses one, and, as the elephant in the room, you have behemoths such as Google, Bing and others. But how do they work? And how can we build our own? And how can we keep it cheap and simple to use?\n",
    "\n",
    "Some of the goals I have while building this search engine:\n",
    "\n",
    "* I'm trying to learn search engines, NLP and non-ML inference\n",
    "* Achieve a decent accuracy\n",
    "\n",
    "Additional challenges since I can't keep things simple 😃:\n",
    "\n",
    "* Fully client side, but without costing the client too much\n",
    "* Strong unicode support - let's support different scriptures and emojis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8dcbfd-3819-4404-93ca-e12411700e14",
   "metadata": {},
   "source": [
    "## Tools Used\n",
    "\n",
    "* Node.js (v22.13.0)\n",
    "* [Enron Emails Dataset](https://www.cs.cmu.edu/~enron/) - used for large scale test data\n",
    "\n",
    "We are using JavaScript since it is easily portable to run on web browsers. I may port the indexer to C++ or Rust in the future if it needs to handle larger amounts of data quickly and more reliably."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639478de-2ce7-433a-b9d2-48c646db94df",
   "metadata": {},
   "source": [
    "## My Initial Thought Process\n",
    "\n",
    "My initial thought process involved me breaking down the search problem into multiple steps.\n",
    "\n",
    "**Indexing:**\n",
    "\n",
    "1. Data acquisition\n",
    "2. Data cleanup and preprocessing\n",
    "3. Determine which words are important and remove filler words\n",
    "4. Index the words\n",
    "5. Store the index\n",
    "\n",
    "**Searching:**\n",
    "\n",
    "1. Clean up and preprocess the query (with the same rules as the data)\n",
    "2. Load the index\n",
    "3. Strip out unimportant words from the query\n",
    "4. Reverse index lookup and ranking\n",
    "5. Emit results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a7428-705e-463c-9ca8-f97b56093804",
   "metadata": {},
   "source": [
    "## Let's Prototype!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaada1-bad2-4517-96ae-f50c5269b838",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Acquisition\n",
    "\n",
    "Data acquisition is arguable the hardest part in building a search engine. For this website, it is a bit simpler. Since I own the content and the transformation from Markdown and HTML to the rendered content, I can mostly skip this step and just clean focus on cleaning up the data.\n",
    "\n",
    "However, as I experiment with search engines, instead of using my own content, I am using the [Enron Emails Dataset](https://www.cs.cmu.edu/~enron/).\n",
    "\n",
    "For the *data acquisition* step, I am recursively walking through the maildir and reading all the files into the index.\n",
    "\n",
    "```javascript\n",
    "async function getAllFiles(dirPath, arrayOfFiles = []) {\n",
    "  const files = await fs.readdir(dirPath);\n",
    "\n",
    "  for (const file of files) {\n",
    "    const filePath = `${dirPath}/${file}`;\n",
    "    const stat = await fs.stat(filePath);\n",
    "\n",
    "    if (stat.isDirectory()) {\n",
    "      await getAllFiles(filePath, arrayOfFiles);\n",
    "    } else {\n",
    "      arrayOfFiles.push(filePath);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  return arrayOfFiles;\n",
    "}\n",
    "\n",
    "(async () => {\n",
    "  const filesList = await getAllFiles('enron-emails');\n",
    "})();\n",
    "```\n",
    "\n",
    "Then, I am reading each file.\n",
    "\n",
    "```javascript\n",
    "import limitFunction from 'p-limit';\n",
    "\n",
    "const limit = limitFunction(100);\n",
    "async function limitedReadFile(path) {\n",
    "  return limit(() => fs.readFile(path, 'utf8'));\n",
    "}\n",
    "...\n",
    "(async () => {\n",
    "\n",
    "  ...\n",
    "    \n",
    "  filesList.forEach(async path => {\n",
    "    try {\n",
    "      const contents = await limitedReadFile(path);\n",
    "      ...\n",
    "    } catch (e) {\n",
    "      console.error('Failed to read file', path, e);\n",
    "    }\n",
    "  });\n",
    "})();\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f33c6-79d8-4a48-b9dd-7a781971841e",
   "metadata": {},
   "source": [
    "### Data Cleanup and Preprocessing\n",
    "\n",
    "In this article, we will keep data cleanup and processing simple and uncomplicated. We will primarily focus on utf-8 transformations. Below is a playground with the code I am using to clean up text! Try editing the `input` variable and see how it gets cleaned up!\n",
    "\n",
    "Additionally, try changing up the regexes, removing regexes or adding regexes to affect the processing.\n",
    "\n",
    "Note: you need web workers enabled for the playground to work."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2bb5023-1355-4528-8741-182545645fa1",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `// https://unicode.org/reports/tr15/\n",
    "function cleanup(string) {\n",
    "  return string\n",
    "    .normalize('NFD')                       // Normalization form, canonical decomposition\n",
    "    // Remove: marks / diacritics, emoji modifiers, punctuation, ZWJ\n",
    "    .replace(/(\\\\p{M}|\\\\p{Emoji_Modifier}|\\\\p{P}|\\\\p{Sc}|\\\\p{Join_Control})/gu, '')\n",
    "    .replace(/(\\\\p{Emoji})/gu, ' $1 ')       // put spaces around emojis so we treat them as words\n",
    "    .replace(/\\\\p{White_Space}/gu, ' ')      // transform whitespace to spaces\n",
    "    .replace(/(\\\\p{Ll})(\\\\p{Lu})/gu, '$1 $2') // split camelCase\n",
    "    .replace(/(\\\\p{N})(\\\\p{L})/gu, '$1 $2')   // split number followed by word without space\n",
    "    .replace(/(\\\\p{L})(\\\\p{N})/gu, '$1 $2')   // split word followed by number without space\n",
    "    .replace(/\\\\s+/gu, ' ')                  // remove extra whitespace between\n",
    "    .toLowerCase();                         // make all text lowercase\n",
    "}\n",
    "\n",
    "const input = 'résumé İSTANBUL ﬁancée 𝟙𝟚𝟛 ½ ¾ ¼ 👩‍🚀🏾🏳️‍🌈🚴🏽‍♂️✌🏿 search2023update multi-word—hyphenated excessive spaces FULLWIDTHＴＥＸＴ 𝒞𝒽𝑒𝓂𝒾𝒸𝒶𝓁 مَرْحَبًا 中文测试 💖✨Unicode✨💖 Hello👩‍💻World 2023年最新情報 परीक्षण προγραμματισμός доброе утро गणना123शब्द '\n",
    "\n",
    "console.log('Before: ', input);\n",
    "console.log('After: ', cleanup(input));\n",
    "`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9e902-b0c4-445f-9418-df677da44ebb",
   "metadata": {},
   "source": [
    "### Next, we generate a word list\n",
    "\n",
    "We split the transformed string by spaces to get a list of words. We are now left with a list of words with which we can work with!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "85f596a9-0bb6-44ac-b1e3-5d841b76be51",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `const input = 'hello, world! lorem ipsum';\n",
    "console.log(JSON.stringify(wordlist(input)));\n",
    "\n",
    "function wordlist(string) {\n",
    "  return string\n",
    "    .split(' ')\n",
    "    .filter(str => str && str.length > 0);\n",
    "}\n",
    "`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24d9ed-9ad8-43b5-a36a-59a3709c06aa",
   "metadata": {},
   "source": [
    "### Putting it all Together"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a6b3ec7-7cdc-4e82-ab3d-b9589c31645a",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `const input = 'résumé İSTANBUL ﬁancée 𝟙𝟚𝟛 ½ ¾ ¼ 👩‍🚀🏾🏳️‍🌈🚴🏽‍♂️✌🏿 search2023update multi-word—hyphenated excessive spaces FULLWIDTHＴＥＸＴ 𝒞𝒽𝑒𝓂𝒾𝒸𝒶𝓁 مَرْحَبًا 中文测试 💖✨Unicode✨💖 Hello👩‍💻World 2023年最新情報 परीक्षण προγραμματισμός доброе утро गणना123शब्द '\n",
    "\n",
    "console.log('Before: ', input);\n",
    "console.log('Trans: ', cleanup(input));\n",
    "console.log('Word list:', wordlist(cleanup(input)));\n",
    "\n",
    "function cleanup(string) {\n",
    "  return string\n",
    "    .normalize('NFD')                       // Normalization form, canonical decomposition\n",
    "    // Remove: marks / diacritics, emoji modifiers, punctuation, ZWJ\n",
    "    .replace(/(\\\\p{M}|\\\\p{Emoji_Modifier}|\\\\p{P}|\\\\p{Sc}|\\\\p{Join_Control})/gu, '')\n",
    "    .replace(/(\\\\p{Emoji})/gu, ' $1 ')       // put spaces around emojis so we treat them as words\n",
    "    .replace(/\\\\p{White_Space}/gu, ' ')      // transform whitespace to spaces\n",
    "    .replace(/(\\\\p{Ll})(\\\\p{Lu})/gu, '$1 $2') // split camelCase\n",
    "    .replace(/(\\\\p{N})(\\\\p{L})/gu, '$1 $2')   // split number followed by word without space\n",
    "    .replace(/(\\\\p{L})(\\\\p{N})/gu, '$1 $2')   // split word followed by number without space\n",
    "    .replace(/\\\\s+/gu, ' ')                  // remove extra whitespace between\n",
    "    .toLowerCase();                         // make all text lowercase\n",
    "}\n",
    "\n",
    "function wordlist(string) {\n",
    "  return string\n",
    "    .split(' ')\n",
    "    .filter(str => str && str.length > 0);\n",
    "}`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899d8c9-b0ca-4402-8a22-4f2cd804e340",
   "metadata": {},
   "source": [
    "## [Next: We will implement a reverse index and search it!](/blog/search-engine-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
