{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522d2439-8858-4618-8870-8b2a12930508",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = 'Devyash Lodha'\n",
    "title = 'Building a Search Engine - Part 1'\n",
    "lastModified = '2025-02-07T20:56:17.277Z'\n",
    "published = '2025-02-07T20:56:17.277Z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeffabb-cc8d-4a2f-ad65-5cc45fbf7d9c",
   "metadata": {},
   "source": [
    "Search engines are a complex beast. This article is about my process of attempting to build one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c375c5-aad4-49af-9015-c1cade9ff464",
   "metadata": {},
   "source": [
    "## Multipart Series\n",
    "\n",
    "1. [Introduction and get started](/blog/search-engine-1)\n",
    "2. [Reverse Index and Search](/blog/search-engine-2)\n",
    "3. [Workshop - Build a Search Engine](/blog/search-engine-3)\n",
    "4. [Workshop - Build a Search Engine (solution)](/blog/search-engine-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc112895-3b68-4a97-ae71-9e14a591d0ae",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "I wanted to add search functionality to this website. However, this site is backend-free, and that is by design! A backend is another service which costs money to run and requires (occasional) maintenance. This article serves as a log of the things I tried and how I developed my solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc61ff0-cb47-49c0-a070-1b822d77ce11",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "Search engines are ubiquitous - almost every major social media platform uses one, and, as the elephant in the room, you have behemoths such as Google, Bing and others. But how do they work? And how can we build our own? And how can we keep it cheap and simple to use?\n",
    "\n",
    "Some goals for this project:\n",
    "\n",
    "* Learn how search engines work\n",
    "* Learn some NLP (natural language processing) techniques\n",
    "* Achieve a decent accuracy\n",
    "\n",
    "Additional challenges and constraints, since I can't keep things simple ðŸ˜ƒ:\n",
    "\n",
    "* Search should have no backend, and be run 100% in the browser\n",
    "* Search should support unicode. Languages other than English exist, oh, and don't forget about Emojis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8dcbfd-3819-4404-93ca-e12411700e14",
   "metadata": {},
   "source": [
    "## Tools Used\n",
    "\n",
    "* Node.js (v22.13.0)\n",
    "* [Enron Emails Dataset](https://www.cs.cmu.edu/~enron/) - used for large scale test data\n",
    "* [Ã†sop's Fables](https://www.gutenberg.org/ebooks/21) - used for test data in our demos\n",
    "\n",
    "> **Notes**:\n",
    "> \n",
    "> 1. for Ã†sop's fables, the text version of the Project Gutenberg archive was transformed into JSON for ease of use. This processing was outside the scope of this article.\n",
    "> 2. The majority of code will be written in JavaScript, due to the goal of being able to run search 100% on the browser."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639478de-2ce7-433a-b9d2-48c646db94df",
   "metadata": {},
   "source": [
    "## The Back-of-the Envelope Search Process\n",
    "\n",
    "When I started working on this article, I thought to myself, how can I implement search? What are some high-level steps required to achieve search? The below steps are my initial idea, and the final form of the search engine may differ slightly from this process due to this article not being updated retroactively.\n",
    "\n",
    "**Indexing:**\n",
    "\n",
    "1. **Data acquisition**: we need to acquire data to index and search somehow\n",
    "2. **Data cleanup and preprocessing**: data is inherently dirty typically. Trying to establish boundaries on the data will help later on\n",
    "3. **Index the words**: unless we want to exhaustively search through all of our content (The Enron email dataset is 1.7 GB, compressed), we need to figure out a better way to structure our content to efficiently find it.\n",
    "\n",
    "**Searching:**\n",
    "\n",
    "1. **Clean up and preprocess the query**\n",
    "2. **Look up the search query in the index**\n",
    "3. **Rank the search results**: some results are better than others\n",
    "4. **Return the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596a7428-705e-463c-9ca8-f97b56093804",
   "metadata": {},
   "source": [
    "## Let's Prototype!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaaada1-bad2-4517-96ae-f50c5269b838",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "\n",
    "Data acquisition is arguable the hardest part in building a search engine. For this website, it is a bit simpler. However, in this project, we are using the [Enron Emails Dataset](https://www.cs.cmu.edu/~enron/). To get all of the corpus text from the Enron email dataset, we can just recursively read the files.\n",
    "\n",
    "```javascript\n",
    "// These functions limit the simultaneous reading of files to prevent exhausting system resouce limits\n",
    "const limit = limitFunction(100);\n",
    "async function limitedReadFile(path) {\n",
    "  return limit(() => fs.readFile(path, 'utf8'));\n",
    "}\n",
    "\n",
    "async function* readFilesRecursively(dir) {\n",
    "  const entries = await fs.readdir(dir, { withFileTypes: true });\n",
    "\n",
    "  for (const entry of entries) {\n",
    "    const fullPath = path.join(dir, entry.name);\n",
    "    if (await entry.isDirectory()) {\n",
    "      yield* readFilesRecursively(fullPath); // Recurse into subdirectory\n",
    "    } else if (entry.isFile()) {\n",
    "      const contents = await limitedReadFile(fullPath);\n",
    "      yield [fullPath, contents];\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "(async () => {\n",
    "  for await (const [ filepath, contents ] of readFilesRecursively(dirPath)) {\n",
    "    // index the filepath and contents\n",
    "  }\n",
    "})();\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8f33c6-79d8-4a48-b9dd-7a781971841e",
   "metadata": {},
   "source": [
    "### Data Cleanup and Preprocessing\n",
    "\n",
    "For now, we will keep the processing a bit shorter and just do unicode normalization and use some regular expressions to clean up some egregious data quality issues.\n",
    "\n",
    "Note that the files in the Enron email dataset are in an email format and contain headers. We will just ignore those for this project."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f2bb5023-1355-4528-8741-182545645fa1",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `// https://unicode.org/reports/tr15/\n",
    "function preprocess(string) {\n",
    "  return string\n",
    "    .normalize('NFD')                       // Normalization form, canonical decomposition\n",
    "    // Remove: marks / diacritics, emoji modifiers, punctuation, ZWJ\n",
    "    .replace(/(\\\\p{M}|\\\\p{Emoji_Modifier}|\\\\p{P}|\\\\p{Sc}|\\\\p{Join_Control})/gu, '')\n",
    "    .replace(/(\\\\p{Emoji})/gu, ' $1 ')       // put spaces around emojis so we treat them as words\n",
    "    .replace(/\\\\p{White_Space}/gu, ' ')      // transform whitespace to spaces\n",
    "    .replace(/(\\\\p{Ll})(\\\\p{Lu})/gu, '$1 $2') // split camelCase\n",
    "    .replace(/(\\\\p{N})(\\\\p{L})/gu, '$1 $2')   // split number followed by word without space\n",
    "    .replace(/(\\\\p{L})(\\\\p{N})/gu, '$1 $2')   // split word followed by number without space\n",
    "    .replace(/\\\\s+/gu, ' ')                  // remove extra whitespace between\n",
    "    .toLowerCase();                         // make all text lowercase\n",
    "}\n",
    "\n",
    "const input = 'rÃ©sumÃ© Ä°STANBUL ï¬ancÃ©e ðŸ™ðŸšðŸ› Â½ Â¾ Â¼ ðŸ‘©â€ðŸš€ðŸ¾ðŸ³ï¸â€ðŸŒˆðŸš´ðŸ½â€â™‚ï¸âœŒðŸ¿ search2023update multi-wordâ€”hyphenated excessive spaces FULLWIDTHï¼´ï¼¥ï¼¸ï¼´ ð’žð’½ð‘’ð“‚ð’¾ð’¸ð’¶ð“ Ù…ÙŽØ±Ù’Ø­ÙŽØ¨Ù‹Ø§ ä¸­æ–‡æµ‹è¯• ðŸ’–âœ¨Unicodeâœ¨ðŸ’– HelloðŸ‘©â€ðŸ’»World 2023å¹´æœ€æ–°æƒ…å ± à¤ªà¤°à¥€à¤•à¥à¤·à¤£ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Ð´Ð¾Ð±Ñ€Ð¾Ðµ ÑƒÑ‚Ñ€Ð¾ à¤—à¤£à¤¨à¤¾123à¤¶à¤¬à¥à¤¦ '\n",
    "\n",
    "console.log('Before: ', input);\n",
    "console.log('After: ', preprocess(input));\n",
    "`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b9e902-b0c4-445f-9418-df677da44ebb",
   "metadata": {},
   "source": [
    "### Next, Lets Tokenize our Cleaned Data\n",
    "\n",
    "> What is a **Token**? Tokens are chunks of text which we treat as a single unit - a word, for example. If a document is a Lego castle, each brick used to build that castle is a token.\n",
    "\n",
    "In this article, tokens will be characters separated by spaces. In lamen terms, a word."
   ]
  },
  {
   "cell_type": "raw",
   "id": "85f596a9-0bb6-44ac-b1e3-5d841b76be51",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `const input = 'hello, world! lorem ipsum';\n",
    "console.log(JSON.stringify(tokenize(input)));\n",
    "\n",
    "function tokenize(string) {\n",
    "  return string\n",
    "    .split(' ')\n",
    "    .filter(str => str && str.length > 0);\n",
    "}\n",
    "`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b24d9ed-9ad8-43b5-a36a-59a3709c06aa",
   "metadata": {},
   "source": [
    "### Putting it all Together"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a6b3ec7-7cdc-4e82-ab3d-b9589c31645a",
   "metadata": {},
   "source": [
    "(() => {\n",
    "    return {\n",
    "        tool: 'code',\n",
    "        props: {\n",
    "            defaultSource: `const input = 'rÃ©sumÃ© Ä°STANBUL ï¬ancÃ©e ðŸ™ðŸšðŸ› Â½ Â¾ Â¼ ðŸ‘©â€ðŸš€ðŸ¾ðŸ³ï¸â€ðŸŒˆðŸš´ðŸ½â€â™‚ï¸âœŒðŸ¿ search2023update multi-wordâ€”hyphenated excessive spaces FULLWIDTHï¼´ï¼¥ï¼¸ï¼´ ð’žð’½ð‘’ð“‚ð’¾ð’¸ð’¶ð“ Ù…ÙŽØ±Ù’Ø­ÙŽØ¨Ù‹Ø§ ä¸­æ–‡æµ‹è¯• ðŸ’–âœ¨Unicodeâœ¨ðŸ’– HelloðŸ‘©â€ðŸ’»World 2023å¹´æœ€æ–°æƒ…å ± à¤ªà¤°à¥€à¤•à¥à¤·à¤£ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Ð´Ð¾Ð±Ñ€Ð¾Ðµ ÑƒÑ‚Ñ€Ð¾ à¤—à¤£à¤¨à¤¾123à¤¶à¤¬à¥à¤¦ '\n",
    "\n",
    "console.log('Before: ', input);\n",
    "console.log('Trans: ', preprocess(input));\n",
    "console.log('Word list:', tokenize(preprocess(input)));\n",
    "\n",
    "function preprocess(string) {\n",
    "  return string\n",
    "    .normalize('NFD')                       // Normalization form, canonical decomposition\n",
    "    // Remove: marks / diacritics, emoji modifiers, punctuation, ZWJ\n",
    "    .replace(/(\\\\p{M}|\\\\p{Emoji_Modifier}|\\\\p{P}|\\\\p{Sc}|\\\\p{Join_Control})/gu, '')\n",
    "    .replace(/(\\\\p{Emoji})/gu, ' $1 ')       // put spaces around emojis so we treat them as words\n",
    "    .replace(/\\\\p{White_Space}/gu, ' ')      // transform whitespace to spaces\n",
    "    .replace(/(\\\\p{Ll})(\\\\p{Lu})/gu, '$1 $2') // split camelCase\n",
    "    .replace(/(\\\\p{N})(\\\\p{L})/gu, '$1 $2')   // split number followed by word without space\n",
    "    .replace(/(\\\\p{L})(\\\\p{N})/gu, '$1 $2')   // split word followed by number without space\n",
    "    .replace(/\\\\s+/gu, ' ')                  // remove extra whitespace between\n",
    "    .toLowerCase();                         // make all text lowercase\n",
    "}\n",
    "\n",
    "function tokenize(string) {\n",
    "  return string\n",
    "    .split(' ')\n",
    "    .filter(str => str && str.length > 0);\n",
    "}`,\n",
    "            autorun: true,\n",
    "            header: false,\n",
    "        }\n",
    "    }\n",
    "})()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d899d8c9-b0ca-4402-8a22-4f2cd804e340",
   "metadata": {},
   "source": [
    "## [Next: We will implement a reverse index and search it!](/blog/search-engine-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
